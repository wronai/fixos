"""
Interaktywny shell LLM do diagnostyki i naprawy systemu Fedora.
Sesja trwa maksymalnie 1 godzinÄ™ (3600 sekund).
Dane diagnostyczne sÄ… wysyÅ‚ane jawnie do modelu.
"""

import signal
import subprocess
import sys
import time
from typing import Optional

try:
    import openai
except ImportError:
    print("[BÅÄ„D] Zainstaluj: pip install openai")
    sys.exit(1)

try:
    from prompt_toolkit import PromptSession
    from prompt_toolkit.styles import Style
    from prompt_toolkit.formatted_text import HTML
except ImportError:
    print("[BÅÄ„D] Zainstaluj: pip install prompt_toolkit")
    sys.exit(1)

from .anonymizer import anonymize

# â”€â”€ StaÅ‚e â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SESSION_TIMEOUT = 3600  # 1 godzina w sekundach
SYSTEM_PROMPT = """JesteÅ› ekspertem od diagnostyki i naprawy systemu Fedora Linux.
Otrzymujesz anonimizowane dane diagnostyczne z systemu uÅ¼ytkownika.

Twoje zadania:
1. Przeanalizuj dane i zidentyfikuj WSZYSTKIE problemy (bÅ‚Ä™dy, ostrzeÅ¼enia, nieaktualne pakiety, failed usÅ‚ugi, przepeÅ‚nione dyski, etc.)
2. Przedstaw problemy jako numerowanÄ… listÄ™, od najpowaÅ¼niejszego
3. Dla kaÅ¼dego problemu zaproponuj KONKRETNÄ„ komendÄ™ naprawczÄ…
4. ZAWSZE pytaj o potwierdzenie przed wykonaniem jakiejkolwiek komendy
5. Informuj o ryzyku kaÅ¼dej operacji

Format odpowiedzi:
ğŸ” DIAGNOZA: [krÃ³tkie podsumowanie]

Wykryte problemy:
1. [opis] â†’ Komenda: `<komenda>`
2. ...

Co naprawiamy? (wpisz numer, 'all', 'skip' lub 'q' aby zakoÅ„czyÄ‡)"""

# â”€â”€ Timeout handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SessionTimeout(Exception):
    pass

def _timeout_handler(signum, frame):
    raise SessionTimeout()


# â”€â”€ Formatowanie czasu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def format_time(seconds: int) -> str:
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    return f"{h:02d}:{m:02d}:{s:02d}"


# â”€â”€ Bezpieczne wykonanie komendy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def execute_command(cmd: str) -> tuple[bool, str]:
    """
    Wykonuje komendÄ™ systemowÄ… z potwierdzeniem uÅ¼ytkownika.
    Zwraca (sukces, output).
    """
    # Komendy wymagajÄ…ce sudo
    dangerous_prefixes = ['dnf', 'rpm', 'systemctl', 'firewall-cmd', 'setenforce',
                          'chmod', 'chown', 'rm ', 'mv ', 'dd ', 'mkfs']
    is_dangerous = any(cmd.strip().startswith(p) for p in dangerous_prefixes)

    if is_dangerous and not cmd.strip().startswith('sudo '):
        cmd = 'sudo ' + cmd.strip()

    print(f"\n  [exec] {cmd}")
    confirm = input("  PotwierdÅº wykonanie (Y/n): ").strip().lower()
    if confirm not in ('y', 'yes', ''):
        return False, "Anulowano przez uÅ¼ytkownika."

    try:
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=120
        )
        output = result.stdout.strip() or result.stderr.strip() or "(brak outputu)"
        success = result.returncode == 0
        status = "âœ… Sukces" if success else f"âŒ BÅ‚Ä…d (kod {result.returncode})"
        print(f"  {status}")
        return success, output
    except subprocess.TimeoutExpired:
        return False, "Komenda przekroczyÅ‚a limit czasu (120s)."
    except Exception as e:
        return False, f"WyjÄ…tek: {e}"


# â”€â”€ GÅ‚Ã³wna funkcja sesji LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_llm_shell(
    diagnostics_data: dict,
    token: str,
    model: str = "gpt-4o-mini",
    timeout: int = SESSION_TIMEOUT,
    verbose: bool = False,
    base_url: Optional[str] = None,
):
    """
    Uruchamia interaktywny shell LLM z przekazanymi danymi diagnostycznymi.
    
    Args:
        diagnostics_data: SÅ‚ownik z danymi diagnostycznymi (przed anonimizacjÄ…)
        token: Klucz API OpenAI lub kompatybilnego serwisu
        model: Nazwa modelu LLM
        timeout: Maksymalny czas sesji w sekundach
        verbose: Czy wyÅ›wietlaÄ‡ dodatkowe informacje debugowania
        base_url: Opcjonalny URL dla alternatywnych API (np. xAI, Ollama)
    """
    # Anonimizuj dane przed wysÅ‚aniem
    anon_data = anonymize(str(diagnostics_data))

    # Konfiguracja klienta OpenAI
    client_kwargs = {"api_key": token}
    if base_url:
        client_kwargs["base_url"] = base_url
    client = openai.OpenAI(**client_kwargs)

    # Konfiguracja timeout
    signal.signal(signal.SIGALRM, _timeout_handler)
    signal.alarm(timeout)
    start_time = time.time()

    # Historia konwersacji
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": (
                f"Oto anonimizowane dane diagnostyczne mojego systemu Fedora:\n\n"
                f"```\n{anon_data}\n```\n\n"
                f"Przeanalizuj je i przedstaw wykryte problemy."
            )
        }
    ]

    # Styl prompt_toolkit
    style = Style.from_dict({
        'prompt': '#00aa00 bold',
        'timer': '#888888',
    })
    session = PromptSession(style=style)

    print("\n" + "â•" * 60)
    print(f"  ğŸ¤– fixfedora LLM Shell  |  Model: {model}")
    print(f"  â° Sesja: max {format_time(timeout)}  |  Wpisz 'q' aby wyjÅ›Ä‡")
    print("â•" * 60 + "\n")

    try:
        while True:
            # Oblicz pozostaÅ‚y czas
            elapsed = int(time.time() - start_time)
            remaining = timeout - elapsed
            if remaining <= 0:
                raise SessionTimeout()

            # WywoÅ‚anie LLM
            print("ğŸ§  LLM analizuje... ", end="", flush=True)
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=2000,
                    temperature=0.3,
                )
                reply = response.choices[0].message.content
                messages.append({"role": "assistant", "content": reply})
            except openai.AuthenticationError:
                print("\nâŒ BÅ‚Ä…d autoryzacji â€“ sprawdÅº token API.")
                break
            except openai.RateLimitError:
                print("\nâš ï¸ Rate limit â€“ poczekaj chwilÄ™...")
                time.sleep(10)
                continue
            except Exception as e:
                print(f"\nâŒ BÅ‚Ä…d API: {e}")
                break

            print("\r" + " " * 25 + "\r", end="")  # wyczyÅ›Ä‡ "analizuje..."
            print(f"\n{'â”€' * 60}")
            print(reply)
            print(f"{'â”€' * 60}")
            print(f"  â° PozostaÅ‚y czas: {format_time(remaining)}")

            # Input uÅ¼ytkownika
            try:
                user_input = session.prompt(
                    HTML(f"\n<prompt>fixfedora</prompt> <timer>[{format_time(remaining)}]</timer> â¯ ")
                ).strip()
            except (EOFError, KeyboardInterrupt):
                print("\n\nSesja przerwana przez uÅ¼ytkownika.")
                break

            if not user_input:
                continue
            if user_input.lower() in ('q', 'quit', 'exit', 'koniec'):
                print("\nâœ… Sesja zakoÅ„czona przez uÅ¼ytkownika.")
                break

            # SprawdÅº czy uÅ¼ytkownik chce wykonaÄ‡ konkretnÄ… komendÄ™
            if user_input.startswith('!'):
                cmd = user_input[1:].strip()
                success, output = execute_command(cmd)
                feedback = f"Wynik komendy `{cmd}`:\n{output}"
                messages.append({"role": "user", "content": feedback})
                if verbose:
                    print(f"\n[DEBUG] Dodano wynik do historii: {feedback[:100]}...")
                continue

            # Normalny input â†’ dodaj do historii i kontynuuj
            messages.append({"role": "user", "content": user_input})

            # JeÅ›li LLM sugeruje komendÄ™ i uÅ¼ytkownik podaÅ‚ numer/all
            if user_input.isdigit() or user_input.lower() == 'all':
                # PoproÅ› LLM o konkretnÄ… komendÄ™ dla wybranego punktu
                messages.append({
                    "role": "user",
                    "content": (
                        f"Podaj TYLKO konkretnÄ… komendÄ™ shell do naprawy problemu {user_input}. "
                        f"Format: `komenda`. Bez opisu."
                    )
                })

    except SessionTimeout:
        print(f"\n\nâ° Sesja wygasÅ‚a po {format_time(timeout)}. PoÅ‚Ä…czenie zakoÅ„czone.")
    finally:
        signal.alarm(0)  # WyÅ‚Ä…cz alarm

    print(f"\n{'â•' * 60}")
    print(f"  ğŸ“Š Podsumowanie sesji: {len(messages) - 2} interakcji w {format_time(elapsed)}")
    print(f"{'â•' * 60}\n")
